{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprot.protein import Protein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load up some proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [\"1A0I\", \"1A49\", \"1A5U\", \"1A82\", \"1AQ2\"] #,\"1ASZ\", \"1ATN\", \"1ATP\", \"1AYL\", \"1B0U\", \"1B38\"]\n",
    "#ids = [\"1A0I\"]\n",
    "proteins = [Protein.fetch(_id) for _id in ids]\n",
    "proteins = list(filter(lambda p: p.df.shape[0] < 5000, proteins))\n",
    "\n",
    "#You can also just pass a file directly:\n",
    "#proteins.append(Protein(\"1i7l.pdb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We automatically have a dataframe of the atoms for each protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteins[0].df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We might want to add some features, a target distance for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "for protein in proteins:\n",
    "    protein.df = protein.df[~protein.df.coord.isnull()]\n",
    "    ATP_coords = protein.df[protein.df.resname == \"ATP\"].coord.to_list()\n",
    "    print(\"Found {} ATP atoms\".format(len(ATP_coords)))\n",
    "    protein.df[\"distance\"] = protein.df.coord.apply(\n",
    "        lambda atom: min(map(lambda atp_atom: np.linalg.norm(atom-atp_atom), ATP_coords))\n",
    "    )\n",
    "    #protein.discard_ligands()\n",
    "    # Sanity check\n",
    "    protein.df = protein.df.loc[\n",
    "        protein.df.apply(lambda row: row[\"full_id\"][4][0] == \"CA\", axis=1),\n",
    "        :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And discard ligands to keep only protein atoms:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for protein in proteins:\n",
    "    chains_with_ligand = protein.df[protein.df.distance <= 6.0].chain.unique()\n",
    "    protein.select_chains(chains_with_ligand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a graph by Delauney triangulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprot.structure import Perseus\n",
    "import pyprot.graph_models as graph_models\n",
    "\n",
    "structures = []\n",
    "graphs = []\n",
    "\n",
    "for i in range(len(proteins)):\n",
    "    print(\"Processing #{} -- shape {}\".format(i, proteins[i].df.shape))\n",
    "    structure = proteins[i].generate_structure(lambda row: row[\"full_id\"][4][0] == \"CA\")\n",
    "    perseus = Perseus()\n",
    "    perseus.execute_persistent_hom(proteins[i])\n",
    "\n",
    "    structure_model = graph_models.StructureGraphGenerator()\n",
    "    proteins[i].generate_graph(structure_model,\n",
    "        {\"step\": structure.persistent_hom_params[\"b3_step\"]})\n",
    "    # Depth features\n",
    "    depths, _ = structure.calculate_depth(proteins[i].graph)\n",
    "    for node_idx, depth in depths.items():\n",
    "        proteins[i].graph.nodes[node_idx][\"depth\"] = depth\n",
    "\n",
    "    # Rest of features\n",
    "    structure_model.add_features(proteins[i].df, columns = [\n",
    "        \"bfactor\", \"resname\", \"x\", \"y\", \"z\", \"distance\"\n",
    "    ])\n",
    "    graphs.append(structure_model)\n",
    "    structures.append(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the structure of a protein\n",
    "proteins[0].structure.plot(proteins[0].structure.persistent_hom_params[\"b3_step\"], 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can turn a graph into a dataframe by propagating features along neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    graph_models.GraphModel.graph_to_dataframe(\n",
    "        graph_models.GraphModel.get_diffused_graph(\n",
    "            p.graph, steps=2, keys=[\"depth\", \"bfactor\"]))\n",
    "    for p in proteins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aaaand we can also make folds using sequence similarity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyprot.groupfolds import CDHitGroup\n",
    "\n",
    "groups = CDHitGroup.get_group(proteins)\n",
    "groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can run a simple model for binding site prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "from sklearn import linear_model\n",
    "import sklearn.preprocessing\n",
    "import pandas\n",
    "\n",
    "\n",
    "for i, df in enumerate(dfs):\n",
    "    df[\"group\"] = groups[i]\n",
    "\n",
    "dataset = pandas.concat(dfs)\n",
    "row_groups = dataset.group\n",
    "row_target = dataset.distance\n",
    "\n",
    "groupk = sklearn.model_selection.GroupKFold(n_splits=2)\n",
    "dataset = dataset.drop([\"distance\", \"group\", \"full_id\"], axis=1)\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = sklearn.preprocessing.OneHotEncoder()\n",
    "onehot_res = enc.fit_transform(dataset.resname.to_numpy().reshape(-1, 1))\n",
    "\n",
    "X = np.concatenate([dataset.drop(\"resname\", axis=1).to_numpy(), onehot_res.todense()], axis=1)\n",
    "\n",
    "row_target = row_target.to_numpy()\n",
    "row_groups = row_groups.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def touches_ligand(x):\n",
    "    \"\"\"Make a soft class boundary by smoothing the distribution\"\"\"\n",
    "    return int(x <= 4 or (x<=6 and np.random.binomial(1, 1-(x-4)/2) == 1))\n",
    "\n",
    "vec_touches = np.vectorize(touches_ligand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_target = vec_touches(row_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in groupk.split(X, row_target, row_groups):\n",
    "    reg = linear_model.Lasso(alpha=0.1)\n",
    "    reg.fit(X[train_index], row_target[train_index])\n",
    "    y_hat = reg.predict(X[test_index])\n",
    "    print(sklearn.metrics.roc_auc_score(row_target[test_index], y_hat))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
